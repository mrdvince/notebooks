{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCQY7jpBfMur"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "z6X9omPnfO_h"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1xIRPtY0E1w"
   },
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyOjQZHhZxaA"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViAXWoKlZ8s6"
   },
   "source": [
    "Keras is a high-level API to build and train deep learning models. It's used for\n",
    "fast prototyping, advanced research, and production, with three key advantages:\n",
    "\n",
    "- *User friendly*<br>\n",
    "  Keras has a simple, consistent interface optimized for common use cases. It\n",
    "  provides clear and actionable feedback for user errors.\n",
    "- *Modular and composable*<br>\n",
    "  Keras models are made by connecting configurable building blocks together,\n",
    "  with few restrictions.\n",
    "- *Easy to extend*<br> Write custom building blocks to express new ideas for\n",
    "  research. Create new layers, loss functions, and develop state-of-the-art\n",
    "  models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsK5aF2xZ-40"
   },
   "source": [
    "## Import tf.keras\n",
    "\n",
    "`tf.keras` is TensorFlow's implementation of the\n",
    "[Keras API specification](https://keras.io). This is a high-level\n",
    "API to build and train models that includes first-class support for\n",
    "TensorFlow-specific functionality, such as [eager execution](#eager_execution),\n",
    "`tf.data` pipelines, and [Estimators](./estimators.md).\n",
    "`tf.keras` makes TensorFlow easier to use without sacrificing flexibility and\n",
    "performance.\n",
    "\n",
    "To get started, import `tf.keras` as part of your TensorFlow program setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qoc055N3wiUG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 19.0.2, however version 19.0.3 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pyyaml  # Required to save models in YAML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgPcBFru0E1z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinc3/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lj03RamP0E13"
   },
   "source": [
    "`tf.keras` can run any Keras-compatible code, but keep in mind:\n",
    "\n",
    "* The `tf.keras` version in the latest TensorFlow release might not be the same\n",
    "  as the latest `keras` version from PyPI. Check `tf.keras.__version__`.\n",
    "* When [saving a model's weights](#weights_only), `tf.keras` defaults to the\n",
    "  [checkpoint format](./checkpoints.md). Pass `save_format='h5'` to\n",
    "  use HDF5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e1LPcXx0gR6"
   },
   "source": [
    "## Build a simple model\n",
    "\n",
    "### Sequential model\n",
    "\n",
    "In Keras, you assemble *layers* to build *models*. A model is (usually) a graph\n",
    "of layers. The most common type of model is a stack of layers: the\n",
    "`tf.keras.Sequential` model.\n",
    "\n",
    "To build a simple, fully-connected network (i.e. multi-layer perceptron):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WM-DUVQB0E14"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ztyTipu0E18"
   },
   "source": [
    "### Configure the layers\n",
    "\n",
    "There are many `tf.keras.layers` available with some common constructor\n",
    "parameters:\n",
    "\n",
    "* `activation`: Set the activation function for the layer. This parameter is\n",
    "  specified by the name of a built-in function or as a callable object. By\n",
    "  default, no activation is applied.\n",
    "* `kernel_initializer` and `bias_initializer`: The initialization schemes\n",
    "  that create the layer's weights (kernel and bias). This parameter is a name or\n",
    "  a callable object. This defaults to the `\"Glorot uniform\"` initializer.\n",
    "* `kernel_regularizer` and `bias_regularizer`: The regularization schemes\n",
    "  that apply the layer's weights (kernel and bias), such as L1 or L2\n",
    "  regularization. By default, no regularization is applied.\n",
    "\n",
    "The following instantiates `tf.keras.layers.Dense` layers using constructor\n",
    "arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlL7PBtp0E19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7fc3c20171d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NR6reyk0E2A"
   },
   "source": [
    "## Train and evaluate\n",
    "\n",
    "### Set up training\n",
    "\n",
    "After the model is constructed, configure its learning process by calling the\n",
    "`compile` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJ4AOn090E2A"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "# Add another:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HG-RAa9F0E2D"
   },
   "source": [
    "`tf.keras.Model.compile` takes three important arguments:\n",
    "\n",
    "* `optimizer`: This object specifies the training procedure. Pass it optimizer\n",
    "  instances from the `tf.train` module, such as\n",
    "  `tf.train.AdamOptimizer`, `tf.train.RMSPropOptimizer`, or\n",
    "  `tf.train.GradientDescentOptimizer`.\n",
    "* `loss`: The function to minimize during optimization. Common choices include\n",
    "  mean square error (`mse`), `categorical_crossentropy`, and\n",
    "  `binary_crossentropy`. Loss functions are specified by name or by\n",
    "  passing a callable object from the `tf.keras.losses` module.\n",
    "* `metrics`: Used to monitor training. These are string names or callables from\n",
    "  the `tf.keras.metrics` module.\n",
    "\n",
    "The following shows a few examples of configuring a model for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "St4Mgdar0E2E"
   },
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjI5rbi80E2G"
   },
   "source": [
    "### Input NumPy data\n",
    "\n",
    "For small datasets, use in-memory [NumPy](https://www.numpy.org/)\n",
    "arrays to train and evaluate a model. The model is \"fit\" to the training data\n",
    "using the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CvP6L-m0E2I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3540 - categorical_accuracy: 0.0790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 2.3146 - categorical_accuracy: 0.0890\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 2.3090 - categorical_accuracy: 0.1060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 151us/step - loss: 2.3111 - categorical_accuracy: 0.1020\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 141us/step - loss: 2.3022 - categorical_accuracy: 0.1260\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 2.2858 - categorical_accuracy: 0.1440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 2.2781 - categorical_accuracy: 0.1290\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 163us/step - loss: 2.2543 - categorical_accuracy: 0.1750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 135us/step - loss: 2.2335 - categorical_accuracy: 0.1500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 162us/step - loss: 2.2111 - categorical_accuracy: 0.1840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3c1537da0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_one_hot_labels(shape):\n",
    "  n, n_class = shape\n",
    "  classes = np.random.randint(0, n_class, n)\n",
    "  labels = np.zeros((n, n_class))\n",
    "  labels[np.arange(n), classes] = 1\n",
    "  return labels\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = random_one_hot_labels((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-pnVaFe0E2N"
   },
   "source": [
    "`tf.keras.Model.fit` takes three important arguments:\n",
    "\n",
    "* `epochs`: Training is structured into *epochs*. An epoch is one iteration over\n",
    "  the entire input data (this is done in smaller batches).\n",
    "* `batch_size`: When passed NumPy data, the model slices the data into smaller\n",
    "  batches and iterates over these batches during training. This integer\n",
    "  specifies the size of each batch. Be aware that the last batch may be smaller\n",
    "  if the total number of samples is not divisible by the batch size.\n",
    "* `validation_data`: When prototyping a model, you want to easily monitor its\n",
    "  performance on some validation data. Passing this argument—a tuple of inputs\n",
    "  and labels—allows the model to display the loss and metrics in inference mode\n",
    "  for the passed data, at the end of each epoch.\n",
    "\n",
    "Here's an example using `validation_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFcXzVQa0E2N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 199us/step - loss: 2.3255 - categorical_accuracy: 0.1050 - val_loss: 2.3221 - val_categorical_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 2.3006 - categorical_accuracy: 0.1050 - val_loss: 2.3592 - val_categorical_accuracy: 0.1200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 166us/step - loss: 2.3044 - categorical_accuracy: 0.1100 - val_loss: 2.3149 - val_categorical_accuracy: 0.0600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.2885 - categorical_accuracy: 0.13 - 0s 140us/step - loss: 2.2895 - categorical_accuracy: 0.1360 - val_loss: 2.3401 - val_categorical_accuracy: 0.1100\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 175us/step - loss: 2.2851 - categorical_accuracy: 0.1240 - val_loss: 2.3539 - val_categorical_accuracy: 0.0100\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 142us/step - loss: 2.2607 - categorical_accuracy: 0.1560 - val_loss: 2.2890 - val_categorical_accuracy: 0.1200\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 147us/step - loss: 2.2412 - categorical_accuracy: 0.1570 - val_loss: 2.3507 - val_categorical_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 2.2125 - categorical_accuracy: 0.1840 - val_loss: 2.3209 - val_categorical_accuracy: 0.1100\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 2.1950 - categorical_accuracy: 0.1970 - val_loss: 2.3493 - val_categorical_accuracy: 0.1500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 166us/step - loss: 2.1773 - categorical_accuracy: 0.2070 - val_loss: 2.4710 - val_categorical_accuracy: 0.0600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3c15374e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = random_one_hot_labels((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = random_one_hot_labels((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6ImyXzz0E2Q"
   },
   "source": [
    "### Input tf.data datasets\n",
    "\n",
    "Use the [Datasets API](./datasets.md) to scale to large datasets\n",
    "or multi-device training. Pass a `tf.data.Dataset` instance to the `fit`\n",
    "method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OziqhpIj0E2R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 2.1407 - categorical_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1056 - categorical_accuracy: 0.2292\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.0675 - categorical_accuracy: 0.2510\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.0419 - categorical_accuracy: 0.2542\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.9990 - categorical_accuracy: 0.2688\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.9606 - categorical_accuracy: 0.2760\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.9302 - categorical_accuracy: 0.2979\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8925 - categorical_accuracy: 0.3167\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8349 - categorical_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8111 - categorical_accuracy: 0.3562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3c01d0828>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7BcMHkB0E2U"
   },
   "source": [
    "Here, the `fit` method uses the `steps_per_epoch` argument—this is the number of\n",
    "training steps the model runs before it moves to the next epoch. Since the\n",
    "`Dataset` yields batches of data, this snippet does not require a `batch_size`.\n",
    "\n",
    "Datasets can also be used for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPMb3A0N0E2V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.8156 - categorical_accuracy: 0.3448 - val_loss: 2.7179 - val_categorical_accuracy: 0.0833\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7482 - categorical_accuracy: 0.3604 - val_loss: 2.7707 - val_categorical_accuracy: 0.0312\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7041 - categorical_accuracy: 0.3979 - val_loss: 2.8149 - val_categorical_accuracy: 0.0312\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7045 - categorical_accuracy: 0.3917 - val_loss: 3.3738 - val_categorical_accuracy: 0.0729\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.6443 - categorical_accuracy: 0.4271 - val_loss: 3.1136 - val_categorical_accuracy: 0.1146\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6521 - categorical_accuracy: 0.4073 - val_loss: 3.5981 - val_categorical_accuracy: 0.1042\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.6231 - categorical_accuracy: 0.4448 - val_loss: 3.4140 - val_categorical_accuracy: 0.0312\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.5952 - categorical_accuracy: 0.4437 - val_loss: 3.2468 - val_categorical_accuracy: 0.0938\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5510 - categorical_accuracy: 0.4583 - val_loss: 3.2180 - val_categorical_accuracy: 0.0833\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5317 - categorical_accuracy: 0.4677 - val_loss: 3.4781 - val_categorical_accuracy: 0.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3c0183940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgGdlXso0E2X"
   },
   "source": [
    "### Evaluate and predict\n",
    "\n",
    "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
    "data and a `tf.data.Dataset`.\n",
    "\n",
    "To *evaluate* the inference-mode loss and metrics for the data provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mhDbOHEK0E2Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 143us/step\n",
      "30/30 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7828988154729208, 0.35625]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = random_one_hot_labels((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXUTmDfb0E2b"
   },
   "source": [
    "And to *predict* the output of the last layer in inference for the data provided,\n",
    "as a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e3JsSoQ0E2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzEOW4Cn0E2h"
   },
   "source": [
    "## Build advanced models\n",
    "\n",
    "### Functional API\n",
    "\n",
    " The `tf.keras.Sequential` model is a simple stack of layers that cannot\n",
    "represent arbitrary models. Use the\n",
    "[Keras functional API](https://keras.io/getting-started/functional-api-guide/)\n",
    "to build complex model topologies such as:\n",
    "\n",
    "* Multi-input models,\n",
    "* Multi-output models,\n",
    "* Models with shared layers (the same layer called several times),\n",
    "* Models with non-sequential data flows (e.g. residual connections).\n",
    "\n",
    "Building a model with the functional API works like this:\n",
    "\n",
    "1. A layer instance is callable and returns a tensor.\n",
    "2. Input tensors and output tensors are used to define a `tf.keras.Model`\n",
    "   instance.\n",
    "3. This model is trained just like the `Sequential` model.\n",
    "\n",
    "The following example uses the functional API to build a simple, fully-connected\n",
    "network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mROj832r0E2i"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))  # Returns a placeholder tensor\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFmspHeG1_W7"
   },
   "source": [
    "Instantiate the model given inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5k5uzlyu16HM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 727us/step - loss: 2.3190 - acc: 0.1030\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 2.3156 - acc: 0.1020\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 157us/step - loss: 2.3093 - acc: 0.1130\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 110us/step - loss: 2.3012 - acc: 0.1250\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 117us/step - loss: 2.2907 - acc: 0.1320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3c0153ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcKSLH3i0E2k"
   },
   "source": [
    "### Model subclassing\n",
    "\n",
    "Build a fully-customizable model by subclassing `tf.keras.Model` and defining\n",
    "your own forward pass. Create layers in the `__init__` method and set them as\n",
    "attributes of the class instance. Define the forward pass in the `call` method.\n",
    "\n",
    "Model subclassing is particularly useful when\n",
    "[eager execution](./eager.md) is enabled since the forward pass\n",
    "can be written imperatively.\n",
    "\n",
    "Key Point: Use the right API for the job. While model subclassing offers\n",
    "flexibility, it comes at a cost of greater complexity and more opportunities for\n",
    "user errors. If possible, prefer the functional API.\n",
    "\n",
    "The following example shows a subclassed `tf.keras.Model` using a custom forward\n",
    "pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLiHWzcn2Fzk"
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_classes=10):\n",
    "    super(MyModel, self).__init__(name='my_model')\n",
    "    self.num_classes = num_classes\n",
    "    # Define your layers here.\n",
    "    self.dense_1 = layers.Dense(32, activation='relu')\n",
    "    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Define your forward pass here,\n",
    "    # using layers you previously defined (in `__init__`).\n",
    "    x = self.dense_1(inputs)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    # You need to override this function if you want to use the subclassed model\n",
    "    # as part of a functional-style model.\n",
    "    # Otherwise, this method is optional.\n",
    "    shape = tf.TensorShape(input_shape).as_list()\n",
    "    shape[-1] = self.num_classes\n",
    "    return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ShDD4fv72KGc"
   },
   "source": [
    "Instantiate the new model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42C-qQHm0E2l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 760us/step - loss: 2.3137 - acc: 0.1080\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 113us/step - loss: 2.3125 - acc: 0.1070\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 108us/step - loss: 2.3090 - acc: 0.1070\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 2.3030 - acc: 0.1030\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 2.2980 - acc: 0.1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3b0517f60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqRQiKj20E2o"
   },
   "source": [
    "### Custom layers\n",
    "\n",
    "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing\n",
    "the following methods:\n",
    "\n",
    "* `build`: Create the weights of the layer. Add weights with the `add_weight`\n",
    "  method.\n",
    "* `call`: Define the forward pass.\n",
    "* `compute_output_shape`: Specify how to compute the output shape of the layer\n",
    "  given the input shape.\n",
    "* Optionally, a layer can be serialized by implementing the `get_config` method\n",
    "  and the `from_config` class method.\n",
    "\n",
    "Here's an example of a custom layer that implements a `matmul` of an input with\n",
    "a kernel matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7BFnIHr2WNc"
   },
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "\n",
    "  def __init__(self, output_dim, **kwargs):\n",
    "    self.output_dim = output_dim\n",
    "    super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "    # Create a trainable weight variable for this layer.\n",
    "    self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=shape,\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "    # Make sure to call the `build` method at the end\n",
    "    super(MyLayer, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    shape = tf.TensorShape(input_shape).as_list()\n",
    "    shape[-1] = self.output_dim\n",
    "    return tf.TensorShape(shape)\n",
    "\n",
    "  def get_config(self):\n",
    "    base_config = super(MyLayer, self).get_config()\n",
    "    base_config['output_dim'] = self.output_dim\n",
    "    return base_config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wXDRgXV2ZrF"
   },
   "source": [
    "Create a model using your custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqH-cY0h0E2p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 636us/step - loss: 2.3046 - acc: 0.1040\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 158us/step - loss: 2.3031 - acc: 0.1160\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 157us/step - loss: 2.3007 - acc: 0.1100\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 125us/step - loss: 2.2990 - acc: 0.1190\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 137us/step - loss: 2.2964 - acc: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3c01d04e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10),\n",
    "    layers.Activation('softmax')])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lu8cc3AJ0E2v"
   },
   "source": [
    "## Callbacks\n",
    "\n",
    "A callback is an object passed to a model to customize and extend its behavior\n",
    "during training. You can write your own custom callback, or use the built-in\n",
    "`tf.keras.callbacks` that include:\n",
    "\n",
    "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at\n",
    "  regular intervals.\n",
    "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning\n",
    "  rate.\n",
    "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation\n",
    "  performance has stopped improving.\n",
    "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using\n",
    "  [TensorBoard](./summaries_and_tensorboard.md).\n",
    "\n",
    "To use a `tf.keras.callbacks.Callback`, pass it to the model's `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdYwzSYV0E2v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 428us/step - loss: 2.2948 - acc: 0.1230 - val_loss: 2.3107 - val_acc: 0.1300\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 159us/step - loss: 2.2925 - acc: 0.1310 - val_loss: 2.3099 - val_acc: 0.1400\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 146us/step - loss: 2.2910 - acc: 0.1250 - val_loss: 2.3099 - val_acc: 0.0900\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 194us/step - loss: 2.2887 - acc: 0.1300 - val_loss: 2.3095 - val_acc: 0.1600\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 205us/step - loss: 2.2866 - acc: 0.1320 - val_loss: 2.3099 - val_acc: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3b01f4668>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghhaGfX62abv"
   },
   "source": [
    "<a id='weights_only'></a>\n",
    "## Save and restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnl7K-aI0E2z"
   },
   "source": [
    "### Weights only\n",
    "\n",
    "Save and load the weights of a model using `tf.keras.Model.save_weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQIANjB94fLB"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eoHJ-ny0E21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7fc39bbccf98>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Restore the model's state,\n",
    "# this requires a model with the same architecture.\n",
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u25Id3xe0E25"
   },
   "source": [
    "By default, this saves the model's weights in the\n",
    "[TensorFlow checkpoint](./checkpoints.md) file format. Weights can\n",
    "also be saved to the Keras HDF5 format (the default for the multi-backend\n",
    "implementation of Keras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSAYoFEd0E26"
   },
   "outputs": [],
   "source": [
    "# Save weights to a HDF5 file\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "\n",
    "# Restore the model's state\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mje_yKL10E29"
   },
   "source": [
    "### Configuration only\n",
    "\n",
    "A model's configuration can be saved—this serializes the model architecture\n",
    "without any weights. A saved configuration can recreate and initialize the same\n",
    "model, even without the code that defined the original model. Keras supports\n",
    "JSON and YAML serialization formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbET0oJTzGkq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_3\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_17\", \"trainable\": true, \"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_18\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.1.6-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize a model to JSON format\n",
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pX_badhH3yWV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'batch_input_shape': [None, 32],\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_17',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_18',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_3'},\n",
      " 'keras_version': '2.1.6-tf'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "pprint.pprint(json.loads(json_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7CIa05r4yTb"
   },
   "source": [
    "Recreate the model (newly initialized) from the JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9UFv9k00E2_"
   },
   "outputs": [],
   "source": [
    "fresh_model = tf.keras.models.model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5NHtICh4uHK"
   },
   "source": [
    "Serializing a model to YAML format requires that you install `pyyaml` *before you import TensorFlow*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj24KB3Z36S4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "  layers:\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: relu\n",
      "      activity_regularizer: null\n",
      "      batch_input_shape: !!python/tuple [null, 32]\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {dtype: float32}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config: {dtype: float32, seed: null}\n",
      "      kernel_regularizer: null\n",
      "      name: dense_17\n",
      "      trainable: true\n",
      "      units: 64\n",
      "      use_bias: true\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: softmax\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {dtype: float32}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config: {dtype: float32, seed: null}\n",
      "      kernel_regularizer: null\n",
      "      name: dense_18\n",
      "      trainable: true\n",
      "      units: 10\n",
      "      use_bias: true\n",
      "  name: sequential_3\n",
      "keras_version: 2.1.6-tf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O53Kerfl43v7"
   },
   "source": [
    "Recreate the model from the YAML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77yRuwg03_MG"
   },
   "outputs": [],
   "source": [
    "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPvOSSzM0E3B"
   },
   "source": [
    "Caution: Subclassed models are not serializable because their architecture is\n",
    "defined by the Python code in the body of the `call` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iu8qMwld4-71"
   },
   "source": [
    "\n",
    "### Entire model\n",
    "\n",
    "The entire model can be saved to a file that contains the weight values, the\n",
    "model's configuration, and even the optimizer's configuration. This allows you\n",
    "to checkpoint a model and resume training later—from the exact same\n",
    "state—without access to the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45oNY34Z0E3C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3078 - acc: 0.1020\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 2.3049 - acc: 0.1040\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 108us/step - loss: 2.3030 - acc: 0.1220\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 133us/step - loss: 2.3016 - acc: 0.1250\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 146us/step - loss: 2.3008 - acc: 0.1310\n"
     ]
    }
   ],
   "source": [
    "# Create a trivial model\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Recreate the exact same model, including weights and optimizer.\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMOWhDOB0E3E"
   },
   "source": [
    "## Eager execution\n",
    "\n",
    "[Eager execution](./eager.md) is an imperative programming\n",
    "environment that evaluates operations immediately. This is not required for\n",
    "Keras, but is supported by `tf.keras` and useful for inspecting your program and\n",
    "debugging.\n",
    "\n",
    "All of the `tf.keras` model-building APIs are compatible with eager execution.\n",
    "And while the `Sequential` and functional APIs can be used, eager execution\n",
    "especially benefits *model subclassing* and building *custom layers*—the APIs\n",
    "that require you to write the forward pass as code (instead of the APIs that\n",
    "create models by assembling existing layers).\n",
    "\n",
    "See the [eager execution guide](./eager.md#build_a_model) for\n",
    "examples of using Keras models with custom training loops and `tf.GradientTape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wG3NVco5B5V"
   },
   "source": [
    "## Distribution\n",
    "\n",
    "### Estimators\n",
    "\n",
    "The [Estimators](./estimators.md) API is used for training models\n",
    "for distributed environments. This targets industry use cases such as\n",
    "distributed training on large datasets that can export a model for production.\n",
    "\n",
    "A `tf.keras.Model` can be trained with the `tf.estimator` API by converting the\n",
    "model to an `tf.estimator.Estimator` object with\n",
    "`tf.keras.estimator.model_to_estimator`. See\n",
    "[Creating Estimators from Keras models](./estimators.md#creating_estimators_from_keras_models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVg0vfTO0E3E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp0zfxo0go\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp0zfxo0go', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc39bb6b7b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([layers.Dense(10,activation='softmax'),\n",
    "                          layers.Dense(10,activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "estimator = tf.keras.estimator.model_to_estimator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S7FKvikO0E3H"
   },
   "source": [
    "Note: Enable [eager execution](./eager.md) for debugging\n",
    "[Estimator input functions](./premade_estimators.md#create_input_functions)\n",
    "and inspecting data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PJZ6e9J5JHF"
   },
   "source": [
    "### Multiple GPUs\n",
    "\n",
    "`tf.keras` models can run on multiple GPUs using\n",
    "`tf.contrib.distribute.DistributionStrategy`. This API provides distributed\n",
    "training on multiple GPUs with almost no changes to existing code.\n",
    "\n",
    "Currently, `tf.contrib.distribute.MirroredStrategy` is the only supported\n",
    "distribution strategy. `MirroredStrategy` does in-graph replication with\n",
    "synchronous training using all-reduce on a single machine. To use\n",
    "`DistributionStrategy` with Keras, convert the `tf.keras.Model` to a\n",
    "`tf.estimator.Estimator` with `tf.keras.estimator.model_to_estimator`, then\n",
    "train the estimator\n",
    "\n",
    "The following example distributes a `tf.keras.Model` across multiple GPUs on a\n",
    "single machine.\n",
    "\n",
    "First, define a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbaRr7g-0E3I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.2)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yw4hSJme0E3L"
   },
   "source": [
    "Define an *input pipeline*. The `input_fn` returns a `tf.data.Dataset` object\n",
    "used to distribute the data across multiple devices—with each device processing\n",
    "a slice of the input batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxJW1QMH0E3L"
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "  x = np.random.random((1024, 10))\n",
    "  y = np.random.randint(2, size=(1024, 1))\n",
    "  x = tf.cast(x, tf.float32)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "  dataset = dataset.repeat(10)\n",
    "  dataset = dataset.batch(32)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO9MiL6X0E3O"
   },
   "source": [
    "Next, create a `tf.estimator.RunConfig` and set the `train_distribute` argument\n",
    "to the `tf.contrib.distribute.MirroredStrategy` instance. When creating\n",
    "`MirroredStrategy`, you can specify a list of devices or set the `num_gpus`\n",
    "argument. The default uses all available GPUs, like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEwFq4PM0E3P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.contrib.distribute.MirroredStrategy()\n",
    "config = tf.estimator.RunConfig(train_distribute=strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcnwYVun0E3R"
   },
   "source": [
    "Convert the Keras model to a `tf.estimator.Estimator` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSvbuIID0E3S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7fc38d46a978>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc38d46ab70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
     ]
    }
   ],
   "source": [
    "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
    "  keras_model=model,\n",
    "  config=config,\n",
    "  model_dir='/tmp/model_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6BXU5F90E3U"
   },
   "source": [
    "Finally, train the `Estimator` instance by providing the `input_fn` and `steps`\n",
    "arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKoJ2wUH0E3U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\n",
      "WARNING:tensorflow:Not all devices in DistributionStrategy are visible to TensorFlow session.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/model_dir/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('/tmp/model_dir/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense_23/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_23/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_24/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_24/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/model_dir/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.71503776, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /tmp/model_dir/model.ckpt.\n",
      "INFO:tensorflow:Finalize system.\n",
      "INFO:tensorflow:Loss for final step: 0.6912508.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fc38c433860>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_estimator.train(input_fn=input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "keras.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
