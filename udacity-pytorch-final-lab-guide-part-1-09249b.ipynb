{"cells":[{"metadata":{"_uuid":"bed9adf7a89aa3ed454670ac2221c30a08079064"},"cell_type":"markdown","source":"# Udacity PyTorch Scholarship Final Lab Challenge Guide  \n**A hands-on guide to get 90% + accuracy and complete the challenge**"},{"metadata":{"_uuid":"918bd7713ae2cc45944a74b6bfcd064b52286a58"},"cell_type":"markdown","source":"**By [Soumya Ranjan Behera](https://www.linkedin.com/in/soumya044)**"},{"metadata":{"_uuid":"c57dc24a29a07511c1460c82f0dd4476ec9022d5"},"cell_type":"markdown","source":"## This Tutorial will be divided into Two Parts,  \n### [1. Model Building and Training](https://www.kaggle.com/soumya044/udacity-pytorch-final-lab-guide-part-1/)\n### [2. Submit in Udcaity's Workspace for evaluation](https://www.kaggle.com/soumya044/udacity-pytorch-final-lab-guide-part-2/)"},{"metadata":{"_uuid":"11ee4ffd8e844a502dc21125fbf8ff4c73999806"},"cell_type":"markdown","source":"**Note:** This tutorial is like a template or guide for newbies to overcome the fear of the final lab challenge. My intent is not to promote plagiarism or any means of cheating. Users are encourage to take this tutorial as a baseline and build their own better model. Cheers!"},{"metadata":{"_uuid":"87a10e21e5b58e4ea1cbe96899723736b3031b79"},"cell_type":"markdown","source":"**Fork this Notebook and Run it from Top-To-Bottom Step by Step**"},{"metadata":{"_uuid":"6d0f0f8864209c8c83e045cd40da9688c9f2f550"},"cell_type":"markdown","source":"# Part 1: Build and Train a Model"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Credits:** The dataset credit goes to [Lalu Erfandi Maula Yusnu](https://www.kaggle.com/nunenuh)"},{"metadata":{"_uuid":"65fd9cd740e3aa705e26adc4344d82a45b225d67"},"cell_type":"markdown","source":"## 1. Import Data set and visualiza some data"},{"metadata":{"trusted":true,"_uuid":"5b2b67269746413105978a5a525236d92e9a4953"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"472663dd61f80c280ec7fb2c74f27367488e0a28"},"cell_type":"markdown","source":"**Import some visualization Libraries**"},{"metadata":{"trusted":true,"_uuid":"1adb9fd10a9c1ef030de746337d4ba85830aff8a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"235fd5978593742bfa855b3d13fe662fe2495b08"},"cell_type":"code","source":"# Set Train and Test Directory Variables\nTRAIN_DATA_DIR = \"../input/flower_data/flower_data/train/\"\nVALID_DATA_DIR = \"../input/flower_data/flower_data/valid/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df0b0737dc0199502e782f88096f16cc779d137e"},"cell_type":"code","source":"#Visualiza Some Images of any Random Directory-cum-Class\nFILE_DIR = str(np.random.randint(1,103))\nprint(\"Class Directory: \",FILE_DIR)\nfor file_name in os.listdir(os.path.join(TRAIN_DATA_DIR, FILE_DIR))[1:3]:\n    img_array = cv2.imread(os.path.join(TRAIN_DATA_DIR, FILE_DIR, file_name))\n    img_array = cv2.resize(img_array,(224, 224), interpolation = cv2.INTER_CUBIC)\n    plt.imshow(img_array)\n    plt.show()\n    print(img_array.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abac0f6abad584517e242c0bc4645794eda705a4"},"cell_type":"markdown","source":"## 2. Data Preprocessing (Image Augmentation)"},{"metadata":{"_uuid":"f799dc0b5302d4bbb78446973c18ac913eaaaf22"},"cell_type":"markdown","source":"**Import PyTorch libraries**"},{"metadata":{"trusted":true,"_uuid":"c643002c28ad352275cea36db421c844259d07fa"},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\ntorch.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9867a090606bed710936a1d85f01f495bd26c6f8"},"cell_type":"markdown","source":"**Note:** **Look carefully! Kaggle uses v1.0.0 while Udcaity workspace has v0.4.0 (Some issues may arise but we'll solve them)**"},{"metadata":{"trusted":true,"_uuid":"28e4419547cc331631ce022fbeb2072b8e15ca33"},"cell_type":"code","source":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43af9fc152eba23cd6192b7913166d1c53530ba4"},"cell_type":"markdown","source":"**Make a Class Variable i.e a list of Target Categories (List of 102 species) **"},{"metadata":{"trusted":true,"_uuid":"a6c7ce913564430a8174b4fee98d0b4ab437e51b"},"cell_type":"code","source":"# I used os.listdir() to maintain the ordering \nclasses = os.listdir(VALID_DATA_DIR)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3591289209e667ce0eef518cb19a9ca7ec014f7d"},"cell_type":"markdown","source":"**Load and Transform (Image Augmentation)**  \nSoucre: https://github.com/udacity/deep-learning-v2-pytorch/blob/master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_augmentation.ipynb"},{"metadata":{"trusted":true,"_uuid":"8a5d64cbe8e232f7c41685c2ffd96ff9492db074"},"cell_type":"code","source":"# Load and transform data using ImageFolder\n\n# VGG-16 Takes 224x224 images as input, so we resize all of them\ndata_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])])\n\ntrain_data = datasets.ImageFolder(TRAIN_DATA_DIR, transform=data_transform)\ntest_data = datasets.ImageFolder(VALID_DATA_DIR, transform=data_transform)\n\n# print out some data stats\nprint('Num training images: ', len(train_data))\nprint('Num test images: ', len(test_data))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e7af3cfd55d0b3cc23c821f951919dd9a9e7c98"},"cell_type":"markdown","source":"### Find more on Image Transforms using PyTorch Here (https://pytorch.org/docs/stable/torchvision/transforms.html)"},{"metadata":{"_uuid":"bcb5d1ddfc6d295c835d8556aec1b14ad0a2dd6e"},"cell_type":"markdown","source":"## 3. Make a DataLoader"},{"metadata":{"trusted":true,"_uuid":"5bc7ebec9b8df421008eea905e84bad1dd51c831","_kg_hide-output":true},"cell_type":"code","source":"# define dataloader parameters\nbatch_size = 32\nnum_workers=0\n\n# prepare data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n                                           num_workers=num_workers, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n                                          num_workers=num_workers, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dd07230720a4fdf6cde314b95918e2ff7b5b419"},"cell_type":"markdown","source":"**Visualize Sample Images**"},{"metadata":{"trusted":true,"_uuid":"2e5326fcec5d0978412871ade97ce294a7c22792"},"cell_type":"code","source":"# Visualize some sample data\n\n# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(classes[labels[idx]])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"944608199404abac32383a293f6f426aa92fb766"},"cell_type":"markdown","source":"**Here plt.imshow() clips our data into [0,....,255] range to show the images. The Warning message is due to our Transform Function. We can Ignore it.**"},{"metadata":{"_uuid":"20806c4fc7e8116217cbda2044e558ee576f2f68"},"cell_type":"markdown","source":"## 4. Use a Pre-Trained Model (VGG16)   \nHere we used a VGG16. You can experiment with other models.  \nReferences: https://github.com/udacity/deep-learning-v2-pytorch/blob/master/transfer-learning/Transfer_Learning_Solution.ipynb"},{"metadata":{"_uuid":"9deaa56e304074b81db7b0ce3000f0afe2951813"},"cell_type":"markdown","source":"**Try More Models: ** https://pytorch.org/docs/stable/torchvision/models.html"},{"metadata":{"trusted":true,"_uuid":"e608b74eec8c351e8001a2ebac3b36c01d1eeb20","_kg_hide-output":true},"cell_type":"code","source":"# Load the pretrained model from pytorch\nmodel = models.<ModelNameHere>(pretrained=True)  \nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd10c0b0c50819cfed95a752060ca3944c899096"},"cell_type":"markdown","source":"### We can see from above output that the last ,i.e, 6th Layer is a Fully-connected Layer with in_features=4096, out_features=1000"},{"metadata":{"trusted":true,"_uuid":"678566270e6e38d5927a4892d640fa33580fd030","_kg_hide-output":true},"cell_type":"code","source":"print(model.classifier[6].in_features) \nprint(model.classifier[6].out_features)\n# The above lines work for vgg only. For other models refer to print(model) and look for last FC layer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2b161235f38790abc92935140c11176ca32be7c"},"cell_type":"markdown","source":"**Freeze Training for all 'Features Layers', Only Train Classifier Layers**"},{"metadata":{"trusted":true,"_uuid":"7452db9de966cd73ded9c31b00f45e8fc468b67a","_kg_hide-output":true},"cell_type":"code","source":"# Freeze training for all \"features\" layers\nfor param in model.features.parameters():\n    param.requires_grad = False\n\n\n#For models like ResNet or Inception use the following,\n\n# Freeze training for all \"features\" layers\n#     for _, param in model.named_parameters():\n#         param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0eaca82048da8cb3dbb274ad3a959333a76e3698"},"cell_type":"markdown","source":"## Let's Add our own Last Layer which will have 102 out_features for 102 species"},{"metadata":{"trusted":true,"_uuid":"30122f9c5c1e1b91bf800c21a7f77a1710e88f30","_kg_hide-output":true},"cell_type":"code","source":"# VGG16  \nn_inputs = model.classifier[6].in_features\n\n#Others\n# n_inputs = model.fc.in_features\n\n# add last linear layer (n_inputs -> 102 flower classes)\n# new layers automatically have requires_grad = True\nlast_layer = nn.Linear(n_inputs, len(classes))\n\n# VGG16\nmodel.classifier[6] = last_layer\n\n# Others\n#model.fc = last_layer\n\n# if GPU is available, move the model to GPU\nif train_on_gpu:\n    model.cuda()\n\n# check to see that your last layer produces the expected number of outputs\n\n#VGG\nprint(model.classifier[6].out_features)\n#Others\n#print(model.fc.out_features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39174d9e7d7dca7cbb7a8e1416ed8ac23a8dc076"},"cell_type":"markdown","source":"# 5. Specify our Loss Function and Optimzer"},{"metadata":{"trusted":true,"_uuid":"58d6265f428ac54a48e91f3443e2ecf9edc4ea88","_kg_hide-output":true},"cell_type":"code","source":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = #TODO\n\n# specify optimizer (stochastic gradient descent) and learning rate = 0.01 or 0.001\noptimizer = #TODO","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3ab068ea23815007e2588fc9020329b3df7de1b"},"cell_type":"markdown","source":"# 6. Train our Model and Save necessary checkpoints"},{"metadata":{"trusted":true,"_uuid":"5f6d82997a281d35613416f841aa835e612b9662","_kg_hide-output":true},"cell_type":"code","source":"# Define epochs (between 50-200)\nepochs = 20\n# initialize tracker for minimum validation loss\nvalid_loss_min = np.Inf # set initial \"min\" to infinity\n\n# Some lists to keep track of loss and accuracy during each epoch\nepoch_list = []\ntrain_loss_list = []\nval_loss_list = []\ntrain_acc_list = []\nval_acc_list = []\n# Start epochs\nfor epoch in range(epochs):\n    \n    #adjust_learning_rate(optimizer, epoch)\n    \n    # monitor training loss\n    train_loss = 0.0\n    val_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    # Set the training mode ON -> Activate Dropout Layers\n    model.train() # prepare model for training\n    # Calculate Accuracy         \n    correct = 0\n    total = 0\n    \n    # Load Train Images with Labels(Targets)\n    for data, target in train_loader:\n        \n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        \n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        \n        if type(output) == tuple:\n            output, _ = output\n        \n        # Calculate Training Accuracy \n        predicted = torch.max(output.data, 1)[1]        \n        # Total number of labels\n        total += len(target)\n        # Total correct predictions\n        correct += (predicted == target).sum()\n        \n        # calculate the loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item()*data.size(0)\n    \n    # calculate average training loss over an epoch\n    train_loss = train_loss/len(train_loader.dataset)\n    \n    # Avg Accuracy\n    accuracy = 100 * correct / float(total)\n    \n    # Put them in their list\n    train_acc_list.append(accuracy)\n    train_loss_list.append(train_loss)\n    \n        \n    # Implement Validation like K-fold Cross-validation \n    \n    # Set Evaluation Mode ON -> Turn Off Dropout\n    model.eval() # Required for Evaluation/Test\n\n    # Calculate Test/Validation Accuracy         \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n\n\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n\n            # Predict Output\n            output = model(data)\n            if type(output) == tuple:\n                output, _ = output\n\n            # Calculate Loss\n            loss = criterion(output, target)\n            val_loss += loss.item()*data.size(0)\n            # Get predictions from the maximum value\n            predicted = torch.max(output.data, 1)[1]\n\n            # Total number of labels\n            total += len(target)\n\n            # Total correct predictions\n            correct += (predicted == target).sum()\n    \n    # calculate average training loss and accuracy over an epoch\n    val_loss = val_loss/len(test_loader.dataset)\n    accuracy = 100 * correct/ float(total)\n    \n    # Put them in their list\n    val_acc_list.append(accuracy)\n    val_loss_list.append(val_loss)\n    \n    # Print the Epoch and Training Loss Details with Validation Accuracy   \n    print('Epoch: {} \\tTraining Loss: {:.4f}\\t Val. acc: {:.2f}%'.format(\n        epoch+1, \n        train_loss,\n        accuracy\n        ))\n    # save model if validation loss has decreased\n    if val_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        val_loss))\n        # Save Model State on Checkpoint\n        torch.save(model.state_dict(), 'model.pt')\n        valid_loss_min = val_loss\n    # Move to next epoch\n    epoch_list.append(epoch + 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a603c247aa9e14c2f93fa06c4592efbc59617d6b"},"cell_type":"markdown","source":"## Load Model State from Checkpoint"},{"metadata":{"trusted":true,"_uuid":"69b42b3fc8d99e0523834476a8c48e69b5eddb7d","_kg_hide-output":true},"cell_type":"code","source":"model.load_state_dict(torch.load('model.pt'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3af4e404b85f76dfc96dddc8dcb6505ec16fe68"},"cell_type":"markdown","source":"## Save the whole Model (Pickling)"},{"metadata":{"trusted":true,"_uuid":"f4f51e0a0fd1f520b74866e108e7f7bb9e2700ac","_kg_hide-output":true},"cell_type":"code","source":"#Save/Pickle the Model\ntorch.save(model, 'classifier.pth')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abded35d366a0a2931bd2658b1868ddb806fb8f6"},"cell_type":"markdown","source":"# 7. Visualize Model Training and Validation"},{"metadata":{"trusted":true,"_uuid":"4d94e6af0ce9f9a797f3590555e907aec73b20de","_kg_hide-output":true},"cell_type":"code","source":"# Training / Validation Loss\nplt.plot(epoch_list,train_loss_list)\nplt.plot(val_loss_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training/Validation Loss vs Number of Epochs\")\nplt.legend(['Train', 'Valid'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"257f8e7070db270fa13130228910265b0e3607ae","_kg_hide-output":true},"cell_type":"code","source":"# Train/Valid Accuracy\nplt.plot(epoch_list,train_acc_list)\nplt.plot(val_acc_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Training/Validation Accuracy\")\nplt.title(\"Accuracy vs Number of Epochs\")\nplt.legend(['Train', 'Valid'], loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d15b5c62b8c8b1ff232daa5f637472aa7b2de6de"},"cell_type":"markdown","source":"From the above graphs we get some really impressive results"},{"metadata":{"_uuid":"b64e67bf0f2e25b54ccdaffe8b00b6856553b149"},"cell_type":"markdown","source":"**Overall Accuracy\n**"},{"metadata":{"trusted":true,"_uuid":"ff9166701ea9c6c1f15d9006abdca5de8b834d0d","_kg_hide-output":true},"cell_type":"code","source":"val_acc = sum(val_acc_list[:]).item()/len(val_acc_list)\nprint(\"Validation Accuracy of model = {} %\".format(val_acc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b64fda3eef8abaa0d358a60fa009b275e0a3a80"},"cell_type":"markdown","source":"# 8. Test our Model Performance "},{"metadata":{"trusted":true,"_uuid":"8c95b4253628cd0e1e0ec9cff63b7a16813c40cb","_kg_hide-output":true},"cell_type":"code","source":"# obtain one batch of test images\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\nimg = images.numpy()\n\n# move model inputs to cuda, if GPU available\nif train_on_gpu:\n    images = images.cuda()\n\nmodel.eval() # Required for Evaluation/Test\n# get sample outputs\noutput = model(images)\nif type(output) == tuple:\n            output, _ = output\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(20, 5))\nfor idx in np.arange(12):\n    ax = fig.add_subplot(3, 4, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(img[idx], (1, 2, 0)))\n    ax.set_title(\"Pr: {} Ac: {}\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea4e7a5d46013a6899977d6903d9f4dcd2fa52e1"},"cell_type":"markdown","source":"**We can see that the Correctly Classifies Results are Marked in \"Green\" and the misclassifies ones are \"Red\"**"},{"metadata":{"_uuid":"1e508fc7b4d1b6ee91db34385a7aba0c518cc636"},"cell_type":"markdown","source":"## 8.1 Test our Model Performance with Gabriele Picco's Program"},{"metadata":{"_uuid":"8b1d3f2ac057442aa86b7c3d1d4c78de0234b6d8"},"cell_type":"markdown","source":"**Credits: ** **Gabriele Picco** (https://github.com/GabrielePicco/deep-learning-flower-identifier)"},{"metadata":{"_uuid":"f4f51eca63a3dea2416b12a90e90834b57d5f04e"},"cell_type":"markdown","source":"**Special Instruction:**  \n1. **Uncomment the following two code cells while running the notebook.**\n2. Comment these two blocks while **Commit**, otherwise you will get an error \"Too many Output Files\" in Kaggle Only.\n3. If you find a solution to this then let me know."},{"metadata":{"trusted":true,"_uuid":"241076ccefc6e3bd937b61638679cc1769be236b"},"cell_type":"code","source":"# !git clone https://github.com/GabrielePicco/deep-learning-flower-identifier\n# !pip install airtable\n# import sys\n# sys.path.insert(0, 'deep-learning-flower-identifier')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96efa9f208c2ba93f2b54422adf6aaf7ff951c5c"},"cell_type":"code","source":"# from test_model_pytorch_facebook_challenge import calc_accuracy\n# calc_accuracy(model, input_image_size=224, use_google_testset=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dee662b06a7f4b69153251e7a0b247fdd73c74ac"},"cell_type":"markdown","source":"## **Congrats! We got almost 90% accuracy with just a simple configuration!**  \n(We will get almost 90% accuracy in Gabriele's Test Suite. Just Uncomment above two code cells and see.)"},{"metadata":{"_uuid":"1a62fedf08485f14eb76c5ad79494f8aed0b3b05"},"cell_type":"markdown","source":"# 9. Export our Model Checkpoint File or Model Pickle File"},{"metadata":{"_uuid":"2b08a193e4e75bb4001e19e6bc4380f0dcada407"},"cell_type":"markdown","source":"**Just Right-click on Below link and Copy the Link**  \n**And Proceed to [Part 2 Tutorial](https://www.kaggle.com/soumya044/udacity-pytorch-final-lab-guide-part-2/)**"},{"metadata":{"_uuid":"4e545d4ed59f5d18114b021f0d53f66d58cac9c3"},"cell_type":"markdown","source":"## Links Here:  \n**Model State Checkpoint File: [model.pt](./model.pt)**   (Preferred)  \n**Classifier Pickle File: [classifier.pth](./classifier.pth)**  \n(Right-click on model.pt and copy the link address)  \n\n* If the links don't work then just modify the (link) as ./model.pt or ./classifier.pth"},{"metadata":{"_uuid":"132a413a102bc20433af2757a06196b5dc3cd176"},"cell_type":"markdown","source":"# **Proceed To Part 2: [Click Here](https://www.kaggle.com/soumya044/udacity-pytorch-final-lab-guide-part-2/)**"},{"metadata":{"_uuid":"591edc3796ff5a67bcf94d122357dfc8b27e414c"},"cell_type":"markdown","source":"# Thank You  \n\nIf you liked this kernel please **Upvote**. Don't forget to drop a comment or suggestion.  \n\n### *Soumya Ranjan Behera*\nLet's stay Connected! [LinkedIn](https://www.linkedin.com/in/soumya044)  \n\n**Happy Coding !**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}